import { select, input, confirm } from "@inquirer/prompts";
import os from "node:os";
import path from "node:path";
import OpenAI from "openai";
import fse from "fs-extra";
import { remark } from "remark";
import ora from "ora";

import { systemContent } from "./prompt.js";

async function generate() {
  const componentDir = await input({
    message: "ç”Ÿæˆç»„ä»¶çš„ç›®å½•:",
    default: "src/components",
    required: true,
  });

  const componentDesc = await input({
    message: "ç»„ä»¶æè¿°:",
    default:
      "ç”Ÿæˆä¸€ä¸ª Table çš„ React ç»„ä»¶ï¼Œæœ‰åŒ…å« nameã€ageã€email å±æ€§çš„data æ•°ç»„å‚æ•°",
    required: true,
  });

  const apiKey = await input({
    message: "æ‚¨çš„apiKey:",
    default: "",
    required: true,
  });

  const client = new OpenAI({
    apiKey,
    baseURL: "https://api.302.ai/v1/chat/completions",
  });

  const spinner = ora("ğŸ”¨ AI ç”Ÿæˆä»£ç ä¸­...").start();

  const res = await client.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: systemContent },
      { role: "user", content: componentDesc },
    ],
  });

  spinner.stop();

  const markdown = res.choices[0].message.content || "";

  await remark()
    .use(function (...args) {
      return function (tree: any) {
        let curPath = "";

        for (let i = 0; i < tree.children.length; i++) {
          const node = tree.children[i];
          if (node.type === "heading") {
            curPath = path.join(componentDir, node.children[0].value);
          } else {
            try {
              fse.ensureFileSync(curPath);
              fse.writeFileSync(curPath, node.value);

              console.log("âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼š", curPath);
            } catch (e) {}
          }
        }
      };
    })
    .process(markdown);
}

export default generate;
